{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-80-vZ_L78AQ",
        "ORIUFutk7_Jt",
        "KjHqq1hcakVM",
        "ZPw_JanX8jrs",
        "IW3WGnnCgqWO",
        "Ciy6XBdZAotU",
        "3YIZPcMd73ol",
        "ky7zAk9n2Uh3",
        "D-Ls5Ghm2AFp",
        "bE1Dtohk15yf",
        "ESOiYVy71Q68",
        "xpShTHmf1f8W",
        "bCjYkk2h4fIU",
        "nF-uNRol4lYg",
        "rH7HJdt94p6X",
        "1j2UJGdmGuja"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Based"
      ],
      "metadata": {
        "id": "-80-vZ_L78AQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries / Downloads"
      ],
      "metadata": {
        "id": "ORIUFutk7_Jt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_lg\n",
        "!pip install unidecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p6EOydn5O5c",
        "outputId": "e386d6cb-2cbb-4f49-c785-2a164589194a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-01-30 20:55:02.742434: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pt-core-news-lg==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.4.0/pt_core_news_lg-3.4.0-py3-none-any.whl (568.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.2/568.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from pt-core-news-lg==3.4.0) (3.4.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (6.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (8.1.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (2.25.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (1.0.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (3.0.11)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (21.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (1.10.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (4.4.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (2022.12.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->pt-core-news-lg==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_lg')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.8/dist-packages (1.3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEbztkUKmz7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f25d266-21a4-48a5-f4b3-904b1142a05b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "import spacy\n",
        "import string\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import csr_matrix\n",
        "from ast import literal_eval\n",
        "from unidecode import unidecode\n",
        "import random\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_lg\")"
      ],
      "metadata": {
        "id": "Tz4g7GsACcnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "wStZElnug4QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes"
      ],
      "metadata": {
        "id": "KjHqq1hcakVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model():\n",
        "\n",
        "  def __init__(self, intents_file, entities_file):\n",
        "    json_file = open(intents_file)\n",
        "    self.intents_data = json.load(json_file)\n",
        "    self.entities_data = entities_file\n",
        "    data = []\n",
        "    for intent in self.intents_data[\"intents\"]:\n",
        "      data.append([intent[\"name\"], intent[\"examples\"], intent[\"responses\"]])\n",
        "    self.df = pd.DataFrame(data=data, columns=['name', 'examples', 'responses'])\n",
        "\n",
        "  def preprocess(self, column_name):\n",
        "    self.clean_text(column_name)\n",
        "    tfidf_vectorizer = TfidfVectorizer().fit(self.train_df[column_name])\n",
        "    intents_vector = tfidf_vectorizer.transform(self.train_df[column_name])\n",
        "    return intents_vector\n",
        "    \n",
        "  def clean_text(self, column_name):\n",
        "    lemmatized_texts = []\n",
        "    for txt in self.train_df[column_name]:\n",
        "      txt = re.sub(r'([a-zA-Z])\\1+', r'\\1', txt)\n",
        "      tokens = nltk.word_tokenize(txt, language='portuguese')\n",
        "      no_punct_text = ' '.join([unidecode(token.lower()) for token in tokens if token not in string.punctuation])\n",
        "      doc = nlp(no_punct_text)\n",
        "      lemmas = ' '.join([token.lemma_ for token in doc])\n",
        "      lemmatized_texts.append(lemmas)\n",
        "    self.train_df[column_name] = lemmatized_texts\n",
        "  \n",
        "  def get_user_df(self, column_name, input_text):\n",
        "    user_input = {column_name: [input_text]}\n",
        "    user_df = pd.DataFrame.from_dict(user_input)\n",
        "    return user_df\n",
        "\n",
        "  def get_list_from_df(self, column_name):\n",
        "    data_list = []\n",
        "    for data in self.df[column_name]:\n",
        "      data_list.append(data)\n",
        "    return data_list\n",
        "  \n",
        "  def parse_user_input(self, input):\n",
        "    user_df = self.get_user_df('examples', input)\n",
        "    return user_df\n",
        "\n",
        "  def train_intents(self, intents_file):\n",
        "    continue_bot = True\n",
        "    while continue_bot == True:\n",
        "      user_input = input('')\n",
        "      if user_input != 'sair':\n",
        "        full_df, self.train_df = get_training_data()\n",
        "        user_df = self.parse_user_input(user_input)\n",
        "        prediction = self.predict(user_df, None)\n",
        "        print(f'The BOT predicted the input as {prediction[\"intent\"]}. Is this correct? (y/n)')\n",
        "        check_option = input('').lower()\n",
        "        if check_option == 'n':\n",
        "          option = 0\n",
        "          intents_map = {}\n",
        "          intents = []\n",
        "          options = []\n",
        "          for intent in list(full_df['name'].values):\n",
        "            intents.append(intent)\n",
        "            options.append(option)\n",
        "            print(f\"{option} - {intent}\\n\")\n",
        "            option +=1\n",
        "          print(f'What is the correct intent? Select an option (number only)')\n",
        "          intent_option = input('')\n",
        "          for intent_key,option_num in zip(intents,options):\n",
        "            if int(option_num) == int(intent_option):\n",
        "              self.append_to_json('intents.json', intent_key, user_input)\n",
        "              break\n",
        "        else:\n",
        "          if user_input not in self.train_df['examples'].tolist():\n",
        "            self.append_to_json('intents.json', prediction[\"intent\"], user_input)\n",
        "      else:\n",
        "        continue_bot = False\n",
        "  \n",
        "  def predict(self, user_df, threshold=0.5):\n",
        "    self.train_df = self.df.iloc[:,:2]\n",
        "    self.train_df = self.train_df.loc[self.train_df['name'] != 'fallback']\n",
        "    self.train_df = self.train_df.explode(\"examples\")\n",
        "    self.train_df = pd.concat([self.train_df,user_df])\n",
        "    intents_vector = self.preprocess('examples')\n",
        "    similarities = cosine_similarity(intents_vector[-1], intents_vector).flatten()\n",
        "    ordered_similar_indexes = similarities.argsort()\n",
        "    most_similar_index = ordered_similar_indexes[-2]\n",
        "    print(sorted(similarities)[-2])\n",
        "    if threshold != None:\n",
        "      if sorted(similarities)[-2] > threshold:\n",
        "        user_intent = self.get_intent(most_similar_index)\n",
        "      else:\n",
        "        user_intent = 'fallback'\n",
        "    else:\n",
        "      user_intent = self.get_intent(most_similar_index)\n",
        "    self.train_df = self.train_df.iloc[:-1,:]\n",
        "    bot_response = self.get_bot_response(self.df, user_intent)\n",
        "    return {\"response\": bot_response, \"intent\": user_intent}\n",
        "\n",
        "  def get_intent(self, row_index):\n",
        "    intent_index = self.train_df.columns.get_loc('name')\n",
        "    user_intent = self.train_df.iloc[row_index, intent_index]\n",
        "    return user_intent\n",
        "\n",
        "  def get_response(self, intents_list):\n",
        "    name = intents_list[0]\n",
        "    list_of_intents = self.intents_data[\"intents\"]\n",
        "    for i in list_of_intents:\n",
        "      if i[\"name\"] == name:\n",
        "        result = random.choice(i[\"responses\"])\n",
        "        break\n",
        "    return result\n",
        "  \n",
        "  def get_bot_response(self, df, user_intent):\n",
        "    df = df.loc[df['name'] == user_intent]\n",
        "    response_array = df.iloc[0,2]\n",
        "    random_idx = random.randint(0,len(response_array)-1)\n",
        "    bot_response = response_array[random_idx]\n",
        "    return bot_response\n",
        "  \n",
        "  def append_to_json(self, intents_data, file_name, intent_key, user_input):\n",
        "    for intent in intents_data['intents']:\n",
        "      if intent['name'] == intent_key:\n",
        "        intent['examples'].append(user_input)\n",
        "    with open(file_name, 'w') as json_file:\n",
        "      json.dump(intents_data, json_file, indent=4, separators=(',',': '), ensure_ascii=False)\n",
        "\n",
        "  def check_for_entity_match(self, user_intent, user_entity, user_input):\n",
        "    entity_file = self.get_json_file(\"entities.json\")\n",
        "    user_input = re.sub(r'([a-zA-Z])\\1+', r'\\1', user_input)\n",
        "    tokens = nltk.word_tokenize(user_input, language='portuguese')\n",
        "    match_entity = False\n",
        "    for entry in user_entity[\"entries\"]:\n",
        "      if entry[\"value\"] in tokens:\n",
        "        match_entity = True\n",
        "      else:\n",
        "        for synonym in entry[\"synonyms\"]:\n",
        "          if synonym in tokens:\n",
        "            match_entity = True\n",
        "    return match_entity \n",
        "    \n"
      ],
      "metadata": {
        "id": "BIMUaZoCVSKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training intents (Reinforcement Learning)"
      ],
      "metadata": {
        "id": "ZPw_JanX8jrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model('intents.json','entities.json')\n",
        "\n",
        "model.train_intents()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "dshwzy5d0msu",
        "outputId": "88644d72-f1a4-46b6-d50a-6ccf29633afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ea52f0223b02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'intents.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'entities.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_intents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'intents.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-8f1e88820236>\u001b[0m in \u001b[0;36mtrain_intents\u001b[0;34m(self, intents_file)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mcontinue_bot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcontinue_bot\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'sair'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mfull_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bot Conversation"
      ],
      "metadata": {
        "id": "IW3WGnnCgqWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "continue_bot = True\n",
        "model = Model('intents.json','entities.json')\n",
        "while continue_bot:\n",
        "  user_input = input('')\n",
        "  if user_input != 'sair':\n",
        "    user_df = model.parse_user_input(user_input)\n",
        "    prediction = model.predict(user_df)\n",
        "    print(prediction)\n",
        "  else:\n",
        "    continue_bot = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "8U5xDTrXwONo",
        "outputId": "1c7bf2dc-89c5-489e-8416-166224afc687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "olá\n",
            "1.0\n",
            "{'response': 'Olá. Posso ajudar?', 'intent': 'iniciar'}\n",
            "quero pedir algo pra comer\n",
            "0.5635046256060454\n",
            "{'response': 'Já processarei seu pedido. Um momento.', 'intent': 'comprar_pizza'}\n",
            "brigada\n",
            "0.0\n",
            "{'response': 'Não compreendi. Poderia repetir?', 'intent': 'fallback'}\n",
            "brigadão\n",
            "0.0\n",
            "{'response': 'Não compreendi. Poderia repetir?', 'intent': 'fallback'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-0593c3641824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'intents.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'entities.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcontinue_bot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'sair'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0muser_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_user_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Intents File"
      ],
      "metadata": {
        "id": "Ciy6XBdZAotU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lENmtXOVAqnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/intents.json\" \"/content/drive/MyDrive/\"\n",
        "!cp -r \"/content/entities.json\" \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "U4Ssw9M-BkEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning"
      ],
      "metadata": {
        "id": "3YIZPcMd73ol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries / Downloads"
      ],
      "metadata": {
        "id": "ky7zAk9n2Uh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWcOiz4a2gtz",
        "outputId": "e023d951-45b1-4fe8-a9f9-74f78c4b4f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.8/dist-packages (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torchinfo import summary\n",
        "from torch.optim import AdamW\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "x0PpNl312XiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "FtcJKLIG2swK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes"
      ],
      "metadata": {
        "id": "D-Ls5Ghm2AFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTModel(nn.Module):\n",
        "\n",
        "  def __init__(self, bert):\n",
        "    super(BERTModel, self).__init__()\n",
        "\n",
        "    self.bert = bert\n",
        "\n",
        "    self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.fc1 = nn.Linear(768,512)\n",
        "\n",
        "    self.fc2 = nn.Linear(512, 256)\n",
        "\n",
        "    self.fc3 = nn.Linear(256,128)\n",
        "\n",
        "    self.fc4 = nn.Linear(128, 3)\n",
        "\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self, sent_id, mask):\n",
        "\n",
        "    cls_hs = self.bert(sent_id, attention_mask=mask)[0][:,0]\n",
        "\n",
        "    x = self.fc1(cls_hs)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.fc3(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.fc4(x)\n",
        "\n",
        "    x = self.softmax(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "x0NqPkUi2Fyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "bE1Dtohk15yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  total_preds=[]\n",
        "\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "    if not step == 0:\n",
        "      print(' Batch {:>5,} of {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "      batch = [r.to(device) for r in batch]\n",
        "      sent_id, mask, labels = batch\n",
        "\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      loss = cross_entropy(preds, labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      lr_sch.step()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "  total_preds = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds\n",
        "\n",
        "def get_prediction(text, le):\n",
        "  test_text = [text]\n",
        "  model.eval()\n",
        "\n",
        "  tokens_test_data = tokenizer(\n",
        "      test_text,\n",
        "      max_length = max_seq_len,\n",
        "      padding=True,\n",
        "      truncation=True,\n",
        "      return_token_type_ids=False\n",
        "  )\n",
        "\n",
        "  test_seq = torch.tensor(tokens_test_data['input_ids'])\n",
        "  test_mask = torch.tensor(tokens_test_data['attention_mask'])\n",
        "\n",
        "  preds = None\n",
        "\n",
        "  with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "  preds = np.argmax(preds, axis=1)\n",
        "  print(\"Intent identified: \", le.inverse_transform(preds)[0])\n",
        "  return le.inverse_transform(preds)[0]\n",
        "\n",
        "def get_max_sent_length(df, column_name, visualize=False):\n",
        "  seq_len = [len(seq.split()) for seq in df[column_name].tolist()]\n",
        "  if visualize:\n",
        "    pd.Series(seq_len).hist(bins=10)\n",
        "  return np.max(seq_len)\n",
        "\n",
        "def get_classes(df, column_name):\n",
        "  le = LabelEncoder()\n",
        "  df[column_name] = le.fit_transform(df[column_name])\n",
        "  df[column_name].value_counts(normalize=True)\n",
        "  classes = df[column_name]\n",
        "  return le, classes\n",
        "\n",
        "def get_training_data(file_name):\n",
        "  intents_data = get_json_file(file_name)\n",
        "  full_df = get_df_from_json(intents_data)\n",
        "  train_df = full_df.iloc[:,:2]\n",
        "  train_df = train_df.explode(\"examples\")\n",
        "  return full_df, train_df\n",
        "\n",
        "def get_deep_response(df, message):\n",
        "  user_intent = get_prediction(message, label_encoder)\n",
        "  df = df.loc[df['name'] == user_intent]\n",
        "  response_array = df.iloc[0,2]\n",
        "  random_idx = random.randint(0,len(response_array)-1)\n",
        "  bot_response = response_array[random_idx]\n",
        "  return bot_response, user_intent"
      ],
      "metadata": {
        "id": "_HsS_RfQ17-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load tokenizer/bert"
      ],
      "metadata": {
        "id": "ESOiYVy71Q68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('neuralmind/bert-base-portuguese-cased')"
      ],
      "metadata": {
        "id": "FkyvBWZjegHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert = AutoModel.from_pretrained('neuralmind/bert-base-portuguese-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZYmBzW-eyvf",
        "outputId": "531336cc-f79e-4add-f089-e53ba2a43228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data"
      ],
      "metadata": {
        "id": "xpShTHmf1f8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_df, df = get_training_data('intents.json')"
      ],
      "metadata": {
        "id": "QwEWXi4O0RNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder, train_labels = get_classes(df, 'name')"
      ],
      "metadata": {
        "id": "NHqm_nzXhxt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = get_max_sent_length(df, 'examples')"
      ],
      "metadata": {
        "id": "39xRJ6W4gc2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_tokens = tokenizer(\n",
        "    df['examples'].tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    padding = True,\n",
        "    truncation = True,\n",
        "    return_token_type_ids = False\n",
        ")"
      ],
      "metadata": {
        "id": "kFn_-E6yf95s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_seq = torch.tensor(training_tokens['input_ids'])\n",
        "training_mask = torch.tensor(training_tokens['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())"
      ],
      "metadata": {
        "id": "4tD3wZurhH0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(training_seq, training_mask, train_y)\n",
        "\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "MTldDsjwieFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in bert.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "model = BERTModel(bert)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-2)\n",
        "\n",
        "train_losses = []\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "lr_sch = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
        "\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3E8T-9VkGpz",
        "outputId": "6b977b7e-902a-4133-c2bd-f8e0217314ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "================================================================================\n",
              "Layer (type:depth-idx)                                  Param #\n",
              "================================================================================\n",
              "BERTModel                                               --\n",
              "├─BertModel: 1-1                                        --\n",
              "│    └─BertEmbeddings: 2-1                              --\n",
              "│    │    └─Embedding: 3-1                              (22,881,792)\n",
              "│    │    └─Embedding: 3-2                              (393,216)\n",
              "│    │    └─Embedding: 3-3                              (1,536)\n",
              "│    │    └─LayerNorm: 3-4                              (1,536)\n",
              "│    │    └─Dropout: 3-5                                --\n",
              "│    └─BertEncoder: 2-2                                 --\n",
              "│    │    └─ModuleList: 3-6                             (85,054,464)\n",
              "│    └─BertPooler: 2-3                                  --\n",
              "│    │    └─Linear: 3-7                                 (590,592)\n",
              "│    │    └─Tanh: 3-8                                   --\n",
              "├─Dropout: 1-2                                          --\n",
              "├─ReLU: 1-3                                             --\n",
              "├─Linear: 1-4                                           393,728\n",
              "├─Linear: 1-5                                           131,328\n",
              "├─Linear: 1-6                                           32,896\n",
              "├─Linear: 1-7                                           387\n",
              "├─LogSoftmax: 1-8                                       --\n",
              "================================================================================\n",
              "Total params: 109,481,475\n",
              "Trainable params: 558,339\n",
              "Non-trainable params: 108,923,136\n",
              "================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balance weights in case of unbalanced classes"
      ],
      "metadata": {
        "id": "bCjYkk2h4fIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "\n",
        "weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "cross_entropy = nn.NLLLoss(weight=weights)"
      ],
      "metadata": {
        "id": "cWXt-TRQm7B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune the BERT Model"
      ],
      "metadata": {
        "id": "nF-uNRol4lYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  \n",
        "  print('\\n Epoch {:} / {:}'.format(epoch+1, epochs))\n",
        "\n",
        "  train_loss, _ = train()\n",
        "\n",
        "  train_losses.append(train_loss)\n",
        "\n",
        "  # Reproducible results\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "\n",
        "print(f'\\nTraining Loss: {train_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uURH5p2FqI9K",
        "outputId": "c34b9917-ed8c-4e80-e646-dd7f87c33ed1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 2 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 3 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 4 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 5 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 6 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 7 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 8 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 9 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 10 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 11 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 12 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 13 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 14 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 15 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 16 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 17 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 18 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 19 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 20 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 21 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 22 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 23 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 24 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 25 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 26 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 27 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 28 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 29 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 30 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 31 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 32 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 33 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 34 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 35 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 36 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 37 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 38 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 39 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 40 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 41 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 42 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 43 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 44 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 45 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 46 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 47 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 48 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 49 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 50 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 51 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 52 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 53 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 54 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 55 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 56 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 57 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 58 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 59 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 60 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 61 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 62 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 63 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 64 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 65 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 66 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 67 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 68 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 69 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 70 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 71 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 72 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 73 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 74 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 75 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 76 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 77 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 78 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 79 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 80 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 81 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 82 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 83 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 84 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 85 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 86 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 87 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 88 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 89 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 90 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 91 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 92 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 93 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 94 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 95 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 96 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 97 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 98 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 99 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            " Epoch 100 / 100\n",
            " Batch     1 of     2.\n",
            "\n",
            "Training Loss: 0.092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "rH7HJdt94p6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "continue_bot = True\n",
        "full_df, train_df = get_training_data('intents.json')\n",
        "while continue_bot:\n",
        "  user_input = input('')\n",
        "  if user_input != 'sair':\n",
        "    prediction, _ = get_deep_response(full_df, user_input)\n",
        "    print(prediction)\n",
        "  else:\n",
        "    continue_bot = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "JQ7UN_GhzvwC",
        "outputId": "8efe876d-0bde-4547-afbc-89dbeda762a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pizzaaaaaaa\n",
            "Intent identified:  comprar_pizza\n",
            "Seu pedido é uma ordem.\n",
            "oba, bão?\n",
            "Intent identified:  iniciar\n",
            "Opa. Posso ajudar com algo?\n",
            "quero pedir um alimento\n",
            "Intent identified:  comprar_pizza\n",
            "Seu pedido é uma ordem.\n",
            "quero comer\n",
            "Intent identified:  comprar_pizza\n",
            "Seu pedido é uma ordem.\n",
            "to precisando de algo pra comer\n",
            "Intent identified:  comprar_pizza\n",
            "É pra já!\n",
            "to precisando me alimentar urgentemente\n",
            "Intent identified:  comprar_pizza\n",
            "Já processarei seu pedido. Um momento.\n",
            "exijo que me alimente agora!\n",
            "Intent identified:  finalizar\n",
            "Até a próxima!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-09e225a7dc92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'intents.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcontinue_bot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'sair'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_deep_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Intents"
      ],
      "metadata": {
        "id": "1j2UJGdmGuja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_intents_deep(intents_file):\n",
        "  intents_data = get_json_file(intents_file)\n",
        "  user_input = input('')\n",
        "  if user_input != 'sair':\n",
        "    full_df, _ = get_training_data('intents.json')\n",
        "    prediction = get_deep_response(full_df, user_input)\n",
        "    print(prediction)\n",
        "    print(f'The BOT predicted the input as {prediction[1]}. Is this correct? (y/n)')\n",
        "    check_option = input('').lower()\n",
        "    if check_option == 'n':\n",
        "      option = 0\n",
        "      intents_map = {}\n",
        "      intents = []\n",
        "      options = []\n",
        "      for intent in list(full_df['name'].values):\n",
        "        intents.append(intent)\n",
        "        options.append(option)\n",
        "        print(f\"{option} - {intent}\\n\")\n",
        "        option +=1\n",
        "      print(f'What is the correct intent? Select an option (number only)')\n",
        "      intent_option = input('')\n",
        "      for intent_key,option_num in zip(intents,options):\n",
        "        if int(option_num) == int(intent_option):\n",
        "          append_to_json(intents_data, 'intents.json', intent_key, user_input)\n",
        "          break\n"
      ],
      "metadata": {
        "id": "_G-6-y5uG3_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_intents_deep('intents.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCo_XqCZG4wB",
        "outputId": "4db79582-a010-46f2-f189-c5d6465edc5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aoba\n",
            "Intent identified:  finalizar\n",
            "('Até breve!', 'finalizar')\n",
            "The BOT predicted the input as finalizar. Is this correct? (y/n)\n",
            "n\n",
            "0 - iniciar\n",
            "\n",
            "1 - comprar_pizza\n",
            "\n",
            "2 - finalizar\n",
            "\n",
            "What is the correct intent? Select an option (number only)\n",
            "0\n",
            "iniciar iniciar\n",
            "comprar_pizza iniciar\n",
            "finalizar iniciar\n"
          ]
        }
      ]
    }
  ]
}